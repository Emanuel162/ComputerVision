{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Introduction"],"metadata":{"id":"Cx54MfzHiWpA"}},{"cell_type":"markdown","source":["In this assignment you will implement a Bag Of Visual Words classifier for the Caltech101 dataset, using Histogram of Oriented Gradients as keypoint descriptor.\n","\n","As seen in the lectures, the approach consists of the following steps:\n","1. Building a dictionary of visual words:\n","  - Find all the corners of the training dataset.\n","  - Extract image patches centred at the found keypoints.\n","  - Compute the HOG descriptor of each patch.\n","  - Traing a K-means clustering on all the features.\n","2. Building the BOVW datasets. Since each image will be represented as a histogram of visual words, for each image in the dataset you will have to:\n","  - Find the corners, extract image patches, compute their HOG descriptors.\n","  - Apply the trained k-means on the features to predict their corresponding centroids.\n","  - Summarize the image as a histogram of the predicted centroids.\n","3. Training the histogram classifier."],"metadata":{"id":"5ei-b4cTim9m"}},{"cell_type":"markdown","source":["## Part 1. Implementation of corner detection and description."],"metadata":{"id":"kncW-mUkirX7"}},{"cell_type":"markdown","source":["### Harris corner detection\n","The Harris response image $R$ of an image is given by:\n","\n","$$\n","R = det(M) - k \\ trace(M)^2\n","$$\n","\n","where $k$ is a pre-determined constant (a typical value is k=0.04) and $M$ is the so called \"structure tensor\", given by:\n","\n","$$\n","M =\n","\\begin{bmatrix}\n","    w \\star (I_x^2) & w \\star (I_x I_y) \\\\\n","     w \\star (I_x I_y) &  w \\star (I_y^2)\n","\\end{bmatrix}\n","$$\n","\n","where $I_x$ and $I_y$ are the spatial partial derivatives of the image (for example, computed with a Sobel filter) and $w$ is a convolution kernel used as weighting window (for example, a Gaussian blur with a 5x5 kernel).\n","\n","Since $M$ is 2x2, the determinant and trace can be easily calculated:\n","\n","$$\n","\\begin{align*}\n","det(M) &= M_{00} M_{11} - M_{01} M_{10} \\\\\n","trace(M) &= M_{00} + M_{11}\n","\\end{align*}\n","$$\n","\n","\n","Large values of the response at a given pixel correspond to large values in the eigenvalues of the covariance matrix of the image gradients in the neighborhood of the given pixel. Meaning, large values in the response at a given pixel identify that pixel as a corner.\n","\n","**1 Implement a function that computes the Harris response of an image:**\n","  - Compute the Sobel derivatives $I_x$ and $I_y$\n","  - Compute $I^2_x , I^2_y, I_x I_y$. Note that these are elementwise multiplications, not matrix multiplications.\n","  - Apply Gaussian blur to $I^2_x , I^2_y, I_x I_y$\n","  - Compute and return $R$. Use the given determinant and trace formulas. Again, note that the products in the determinant formula are elementwise products and not matrix products.\n","\n","**2 Implement a corner detection function based on the Harris response.** The function should:\n","  - Identify a corner if the response at the pixel is bigger than some threshold.\n","  - Implement Non-Maximum-Supression, since a single keypoint may be detected by many neighboring pixels. If there are keypoints separated by a distance smaller than `d`,only the pixel with the strongest response should remain.\n","  - Return the coordinates of the detected keypoints.\n","\n","Show the result of your corner detector applied on some image and identifying the detected keypoints.\n","\n","**You can only use numpy and opencv for the implementations**"],"metadata":{"id":"uLoNb8YFxJtB"}},{"cell_type":"code","source":["def compute_harris_response(img, k=0.04):\n","  # grad_x, grad_y = ...\n","  # m_00, m_11, m_01 = ...\n","  # det_m = m_00*m_11 - m_01*m_01\n","  # trace_m = m_00 + m_11\n","  # return det_m - k*trace_m**2\n","  pass\n","\n","def find_keypoints(img, response_threshold, d=10):\n","  pass"],"metadata":{"id":"Ov0fsOSwopsG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","### Histogram of Oriented Gradients\n","\n","**3 Implement a function that given an image patch, returns its HOG descriptor.** The function should:\n","- Compute the Sobel derivatives of the image patch. Compute the derivatives magnitudes and orientations. Make sure that the orientations lie in the range  [0, 2pi).\n","- Divide the patch into a `n_cells` x `n_cells` grid.\n","- For each cell of the grid:\n","  - Compute the sum of gradients magnitudes. Divide the gradients magnitudes by this sum.\n","  - Compute a histogram of gradient orientations, weighted by the below calculated magnitudes. The histogram should have `q` bins that divide [0,2pi) in equally spaced intervals.\n","- The HOG descriptor vector is then the concatenation of the `n_cells` x `n_cells` histograms.\n","\n","The descriptor can be upgraded if the image patch is rectified beforehand. An easy way to do this is to subtract the most frequent gradient orientation from all the gradient orientations.\n"],"metadata":{"id":"b0YF6s_Jook1"}},{"cell_type":"code","source":["def compute_hog_descriptor(img_patch, n_cells=4, q=4):\n","  pass"],"metadata":{"id":"C_9F4at1q0NV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2. Build and train a BOVW classifier"],"metadata":{"id":"Sqz52HaZi2yB"}},{"cell_type":"markdown","source":["First lets download the dataset and split it into a train and test set. We will not use the complete dataset but pick a smaller subset of classes"],"metadata":{"id":"sNvQgMXBqyE8"}},{"cell_type":"code","source":["import os\n","import sklearn\n","import urllib.request\n","import tarfile\n","import zipfile\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","\n","# download dataset\n","filename = 'caltech-101.zip'\n","if not os.path.exists(filename):\n","    url = 'https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip'\n","    urllib.request.urlretrieve(url, filename)\n","\n","    # extract files\n","    with zipfile.ZipFile(filename, 'r') as zip_ref:\n","        zip_ref.extractall('./')\n","\n","    with tarfile.open('./caltech-101/101_ObjectCategories.tar.gz', \"r:gz\") as tar:\n","      tar.extractall()\n","\n","# load with sklearn\n","ds_path = './101_ObjectCategories'\n","ds = sklearn.datasets.load_files(ds_path, allowed_extensions=['.jpg'], load_content=False)\n","fns = ds['filenames']\n","tgts = ds['target']\n","\n","# take some classes\n","filtered_classes = ['faces', 'leopards', 'motorbikes', 'airplanes', 'ketch', 'schooner']\n","\n","# get class ids by name\n","class_names = np.char.lower(ds['target_names'])\n","sorter = np.argsort(class_names)\n","cs = sorter[np.searchsorted(class_names, filtered_classes, sorter=sorter)]\n","\n","idcs = list(map(lambda x: x in cs, tgts))\n","tgts = tgts[idcs]\n","fns = fns[idcs]\n","\n","# filenames and labels for the train and test set images\n","fns_train, fns_test, y_train, y_test = train_test_split(fns, tgts, stratify=tgts,test_size=.20, random_state=42)"],"metadata":{"id":"xnTa0itIyXGh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4 Build the visual words dictionary:**\n","- Find all the keypoints in the training dataset\n","- Extract patches of some pre-defined size (e.g. 32 pixels of side) centred at the keypoints\n","- Compute the HOG descriptor of each image patch.\n","- Train a k-means clustering on the complete set of descriptors (for example, with k=8). Try different values of k.\n","\n","**5 Train a Support Vector Machine classifier.**\n","- First, convert all the images of the dataset into their bag of visual words representation. Given an input image:\n","  - Find the corners, extract image patches, compute their HOG descriptors.\n","  - Apply the trained k-means on the features to predict their corresponding centroids.\n","  - Summarize the image as a histogram of the predicted centroids.\n","- Train a Support Vector Machine classifier using the BOVW representations of the images.\n","  - Use the $\\chi^2$ kernel as kernel function. Make sure that the `gamma` parameter is correctly set as this influences classification performance.\n","\n","**6 Report the results.**\n","- Report classification metrics on the test set and plot the confusion matrix.\n","- Please describe the reported metrices and the confusion matrix. What are your conclusions?\n","\n","**Notes**\n","- Use `sklearn`'s k-means and Support Vector Machine for this exercise. Additionally, you can use any other functionality of `sklearn` if you require.\n","- Caltech101 images come in different size and shapes. Before finding keypoints, you could pre-process each image for example by resizing them to a smaller shape, as big images take longer to process.\n","- Throughout the assignment you had to make some design choices by picking _hyperparameters_ of your algorithm: the detector's NMS distance, HOG's `n_cells` and `q`, the keypoints' patch size, k-means' k, the kernel function's gamma, the pre-processing function, etc. These values have an effect on the classifier's performance, both in training/inference speed and in the classification metrics. **You should try out different values in order to maximize the algorithm's performance.**"],"metadata":{"id":"8YD4EQVfV-3D"}}]}